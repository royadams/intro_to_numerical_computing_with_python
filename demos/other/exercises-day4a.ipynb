{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.feature_extraction.image import PatchExtractor\n",
    "from sklearn.datasets import load_sample_image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import dict_learning_online\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "\n",
    "#Set plots to inline\n",
    "%matplotlib inline\n",
    "\n",
    "#Function for plotting arrays of images\n",
    "def plot_gallery(images, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(0.9 * n_col, 1.2 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        if(len(images[i].shape)==1):\n",
    "          plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray, interpolation='nearest')\n",
    "          plt.clim(-2,2)  \n",
    "        else: \n",
    "          plt.imshow(images[i], cmap=plt.cm.gray, interpolation='nearest')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Prepare the Image Patch Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The Python Imaging Library (PIL) is required to load data from jpeg files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-799e07accf0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load image and convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mload_sample_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flower.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#gray = gray + 0.05*np.random.randn(*gray.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adams/py2/lib/python2.7/site-packages/sklearn/datasets/base.pyc\u001b[0m in \u001b[0;36mload_sample_image\u001b[0;34m(image_name)\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m427\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \"\"\"\n\u001b[0;32m--> 635\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sample_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/adams/py2/lib/python2.7/site-packages/sklearn/datasets/base.pyc\u001b[0m in \u001b[0;36mload_sample_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpilutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         raise ImportError(\"The Python Imaging Library (PIL) \"\n\u001b[0m\u001b[1;32m    592\u001b[0m                           \"is required to load data from jpeg files\")\n\u001b[1;32m    593\u001b[0m     \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: The Python Imaging Library (PIL) is required to load data from jpeg files"
     ]
    }
   ],
   "source": [
    "#Load image and convert to grayscale\n",
    "img  = load_sample_image('flower.jpg')\n",
    "gray = np.mean(img,axis=2)\n",
    "gray = gray/np.max(gray.data)\n",
    "#gray = gray + 0.05*np.random.randn(*gray.shape)\n",
    "\n",
    "\n",
    "#Extract P patches of size SxS\n",
    "S=10;P=8000;\n",
    "pex      = PatchExtractor(patch_size=(S,S), max_patches=P)\n",
    "patches  = pex.transform(gray[np.newaxis,:,:])\n",
    "X        = patches.reshape(P,S*S)\n",
    "\n",
    "#Filter out patches that are too uniform\n",
    "ind      = np.std(X,axis=1)>0.1\n",
    "X        = X[ind,:]\n",
    "\n",
    "Xtest = X[:len(X)/2]\n",
    "X = X[len(X)/2:]\n",
    "\n",
    "m = np.mean(X,0)\n",
    "s = np.std(X,0)\n",
    "X=(X-m)/s\n",
    "Xtest= (Xtest-m)/s\n",
    "\n",
    "#Show the original image\n",
    "plt.figure(1);\n",
    "plt.imshow(gray,cmap='gray')\n",
    "\n",
    "#Show the patches\n",
    "plt.figure(2);\n",
    "plot_gallery(Xtest[0:20], S, S,4,5)\n",
    "\n",
    "h=S; w=S\n",
    "print X.shape\n",
    "print Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA and Show Learned Basis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K=25;\n",
    "pca        = PCA(n_components=K, whiten=False).fit(X)\n",
    "components = pca.components_.reshape((K, h, w))\n",
    "\n",
    "Z = pca.transform(Xtest)\n",
    "Xhat = Z.dot(pca.components_)\n",
    "\n",
    "err  = np.mean(np.mean((Xhat-Xtest)**2))\n",
    "print \"Mean Reconstruction Error Per Pixel: %.4f\"%(err,)\n",
    "\n",
    "Xhat   = Xhat.reshape((Xhat.shape[0], h, w))\n",
    "Xtest2 = Xtest.reshape((Xtest.shape[0], h, w))\n",
    "\n",
    "#Plot basis\n",
    "plot_gallery(components, h, w, 5,5)\n",
    "print(\"PCA Basis\")\n",
    "plt.show()\n",
    "\n",
    "#Plot representation\n",
    "plt.figure(2,figsize=(4,3))\n",
    "plt.imshow(Z[:25,:],interpolation=\"nearest\",cmap=\"bwr\")\n",
    "plt.colorbar()\n",
    "plt.clim(-5,5)\n",
    "plt.title(\"PCA Representation\")\n",
    "plt.xlabel(\"PCA Coefficient\")\n",
    "plt.ylabel(\"Data Instance\")\n",
    "\n",
    "#Plot reconstructions\n",
    "plot_gallery(np.hstack((Xtest2[:25],Xhat[:25])), h, w, 5,5)\n",
    "plt.show()\n",
    "print(\"True and Approximated Patches\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Sparse Coding and Show the Basis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K=50;\n",
    "falpha=1; #value of alpah used to fit model\n",
    "talpha=1; #value of alpha used to tranform data cases\n",
    "\n",
    "sc         = MiniBatchDictionaryLearning(n_components=K, alpha=falpha, transform_alpha=talpha,batch_size=100, fit_algorithm=\"cd\",transform_algorithm=\"lasso_cd\",verbose=True,n_iter=100).fit(X)\n",
    "components = sc.components_.reshape((K, h, w))\n",
    "\n",
    "Z = sc.transform(Xtest)\n",
    "Xhat = Z.dot(sc.components_)\n",
    "err  = np.mean(np.mean((Xhat-Xtest)**2))\n",
    "print \"\\nMean Reconstruction Error Per Pixel: %.4f\"%(err,)\n",
    "\n",
    "Xhat   = Xhat.reshape((Xhat.shape[0], h, w))\n",
    "Xtest2 = Xtest.reshape((Xtest.shape[0], h, w))\n",
    "\n",
    "#Plot basis\n",
    "plot_gallery(components, h, w, 5,5)\n",
    "print(\"Sparse Coding Basis\")\n",
    "plt.show()\n",
    "\n",
    "#Plot representation\n",
    "plt.figure(2,figsize=(4,3))\n",
    "plt.imshow(Z[:25,:],interpolation=\"nearest\",cmap=\"bwr\")\n",
    "plt.colorbar()\n",
    "plt.clim(-6,6)\n",
    "plt.title(\"SC Representation\")\n",
    "plt.xlabel(\"SC Coefficient\")\n",
    "plt.ylabel(\"Data Instance\")\n",
    "\n",
    "#Plot reconstructions\n",
    "plot_gallery(np.hstack((Xtest2[:25],Xhat[:25])), h, w, 5,5)\n",
    "plt.show()\n",
    "print(\"True and Approximated Patches\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "exercises-day4.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
